{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"PyGPT-J API Reference","text":""},{"location":"#pygpt4all.models","title":"pygpt4all.models","text":""},{"location":"#pygpt4all.models.gpt4allj","title":"gpt4allj","text":"<p>GPT4ALL model based on <code>llama.cpp</code> backend</p>"},{"location":"#pygpt4all.models.gpt4allj.GPT4ALLJ","title":"GPT4ALLJ","text":"<pre><code>GPT4ALLJ(model_path, log_level=logging.INFO)\n</code></pre> <p>         Bases: <code>Model</code></p> <p>GPT4ALL-J model</p> <p>Example usage <pre><code>from pygpt4all.models.gpt4all_j import GPT4ALLJ\n\ndef new_text_callback(text):\n    print(text, end=\"\")\n\nmodel = GPT4ALL('./models/ggml-gpt4all-j.bin')\nmodel.generate(\"Once upon a time, \", n_predict=55, new_text_callback=new_text_callback)\n</code></pre></p> <p>Parameters:</p> Name Type Description Default <code>model_path</code> <code>str</code> <p>The path to a gpt4all <code>ggml</code> model</p> required <code>log_level</code> <code>int</code> <p>logging level, set to INFO by default</p> <code>logging.INFO</code> Source code in <code>pygpt4all/models/gpt4allj.py</code> <pre><code>def __init__(self,\n             model_path: str,\n             log_level: int = logging.INFO):\n\"\"\"\n    :param model_path: The path to a gpt4all `ggml` model\n    :param log_level: logging level, set to INFO by default\n    \"\"\"\n    # set logging level\n    set_log_level(log_level)\n    super(GPT4ALLJ, self).__init__(model_path=model_path, log_level=log_level)\n</code></pre>"},{"location":"#pygpt4all.models.gpt4all","title":"gpt4all","text":"<p>GPT4ALL model based on <code>llama.cpp</code> backend</p>"},{"location":"#pygpt4all.models.gpt4all.GPT4ALL","title":"GPT4ALL","text":"<pre><code>GPT4ALL(model_path, log_level=logging.INFO)\n</code></pre> <p>         Bases: <code>Model</code></p> <p>GPT4ALL model</p> <p>Example usage <pre><code>from pygpt4all.models.gpt4all import GPT4ALL\n\ndef new_text_callback(text):\n    print(text, end=\"\")\n\nmodel = GPT4ALL('./models/ggml-gpt4all-j.bin')\nmodel.generate(\"Once upon a time, \", n_predict=55, new_text_callback=new_text_callback)\n</code></pre></p> <p>Parameters:</p> Name Type Description Default <code>model_path</code> <code>str</code> <p>The path to a gpt4all <code>ggml</code> model</p> required <code>log_level</code> <code>int</code> <p>logging level, set to INFO by default</p> <code>logging.INFO</code> Source code in <code>pygpt4all/models/gpt4all.py</code> <pre><code>def __init__(self,\n             model_path: str,\n             log_level: int = logging.INFO):\n\"\"\"\n    :param model_path: The path to a gpt4all `ggml` model\n    :param log_level: logging level, set to INFO by default\n    \"\"\"\n    # set logging level\n    set_log_level(log_level)\n    super(GPT4ALL, self).__init__(ggml_model=model_path, log_level=log_level)\n</code></pre>"}]}